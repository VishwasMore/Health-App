{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required libraries for reading data, analysing and visualizing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training & test data\n",
    "liver_df = pd.read_csv('indian_liver_patient.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65  Female              0.7               0.1                   187   \n",
       "1   62    Male             10.9               5.5                   699   \n",
       "2   62    Male              7.3               4.1                   490   \n",
       "3   58    Male              1.0               0.4                   182   \n",
       "4   72    Male              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        1  \n",
       "1      3.2                        0.74        1  \n",
       "2      3.3                        0.89        1  \n",
       "3      3.4                        1.00        1  \n",
       "4      2.4                        0.40        1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 583 entries, 0 to 582\n",
      "Data columns (total 11 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Age                         583 non-null    int64  \n",
      " 1   Gender                      583 non-null    object \n",
      " 2   Total_Bilirubin             583 non-null    float64\n",
      " 3   Direct_Bilirubin            583 non-null    float64\n",
      " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
      " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
      " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
      " 7   Total_Protiens              583 non-null    float64\n",
      " 8   Albumin                     583 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio  579 non-null    float64\n",
      " 10  Dataset                     583 non-null    int64  \n",
      "dtypes: float64(5), int64(5), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "liver_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>583.000000</td>\n",
       "      <td>583</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>583.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.746141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.298799</td>\n",
       "      <td>1.486106</td>\n",
       "      <td>290.576329</td>\n",
       "      <td>80.713551</td>\n",
       "      <td>109.910806</td>\n",
       "      <td>6.483190</td>\n",
       "      <td>3.141852</td>\n",
       "      <td>0.947064</td>\n",
       "      <td>1.286449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.189833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.209522</td>\n",
       "      <td>2.808498</td>\n",
       "      <td>242.937989</td>\n",
       "      <td>182.620356</td>\n",
       "      <td>288.918529</td>\n",
       "      <td>1.085451</td>\n",
       "      <td>0.795519</td>\n",
       "      <td>0.319592</td>\n",
       "      <td>0.452490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>4929.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age Gender  Total_Bilirubin  Direct_Bilirubin  \\\n",
       "count   583.000000    583       583.000000        583.000000   \n",
       "unique         NaN      2              NaN               NaN   \n",
       "top            NaN   Male              NaN               NaN   \n",
       "freq           NaN    441              NaN               NaN   \n",
       "mean     44.746141    NaN         3.298799          1.486106   \n",
       "std      16.189833    NaN         6.209522          2.808498   \n",
       "min       4.000000    NaN         0.400000          0.100000   \n",
       "25%      33.000000    NaN         0.800000          0.200000   \n",
       "50%      45.000000    NaN         1.000000          0.300000   \n",
       "75%      58.000000    NaN         2.600000          1.300000   \n",
       "max      90.000000    NaN        75.000000         19.700000   \n",
       "\n",
       "        Alkaline_Phosphotase  Alamine_Aminotransferase  \\\n",
       "count             583.000000                583.000000   \n",
       "unique                   NaN                       NaN   \n",
       "top                      NaN                       NaN   \n",
       "freq                     NaN                       NaN   \n",
       "mean              290.576329                 80.713551   \n",
       "std               242.937989                182.620356   \n",
       "min                63.000000                 10.000000   \n",
       "25%               175.500000                 23.000000   \n",
       "50%               208.000000                 35.000000   \n",
       "75%               298.000000                 60.500000   \n",
       "max              2110.000000               2000.000000   \n",
       "\n",
       "        Aspartate_Aminotransferase  Total_Protiens     Albumin  \\\n",
       "count                   583.000000      583.000000  583.000000   \n",
       "unique                         NaN             NaN         NaN   \n",
       "top                            NaN             NaN         NaN   \n",
       "freq                           NaN             NaN         NaN   \n",
       "mean                    109.910806        6.483190    3.141852   \n",
       "std                     288.918529        1.085451    0.795519   \n",
       "min                      10.000000        2.700000    0.900000   \n",
       "25%                      25.000000        5.800000    2.600000   \n",
       "50%                      42.000000        6.600000    3.100000   \n",
       "75%                      87.000000        7.200000    3.800000   \n",
       "max                    4929.000000        9.600000    5.500000   \n",
       "\n",
       "        Albumin_and_Globulin_Ratio     Dataset  \n",
       "count                   579.000000  583.000000  \n",
       "unique                         NaN         NaN  \n",
       "top                            NaN         NaN  \n",
       "freq                           NaN         NaN  \n",
       "mean                      0.947064    1.286449  \n",
       "std                       0.319592    0.452490  \n",
       "min                       0.300000    1.000000  \n",
       "25%                       0.700000    1.000000  \n",
       "50%                       0.930000    1.000000  \n",
       "75%                       1.100000    2.000000  \n",
       "max                       2.800000    2.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are some missing values in Albumin_and_Globulin_Ratio & Gender has 2 values (Male and Female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n",
       "       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n",
       "       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n",
       "       'Albumin_and_Globulin_Ratio', 'Dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Total_Bilirubin               0\n",
       "Direct_Bilirubin              0\n",
       "Alkaline_Phosphotase          0\n",
       "Alamine_Aminotransferase      0\n",
       "Aspartate_Aminotransferase    0\n",
       "Total_Protiens                0\n",
       "Albumin                       0\n",
       "Albumin_and_Globulin_Ratio    4\n",
       "Dataset                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 missing values in Albumin_and_Globulin_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9470639032815201"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df['Albumin_and_Globulin_Ratio'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df = liver_df.fillna(0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Total_Bilirubin               0\n",
       "Direct_Bilirubin              0\n",
       "Alkaline_Phosphotase          0\n",
       "Alamine_Aminotransferase      0\n",
       "Aspartate_Aminotransferase    0\n",
       "Total_Protiens                0\n",
       "Albumin                       0\n",
       "Albumin_and_Globulin_Ratio    0\n",
       "Dataset                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling Gender\n",
    "\n",
    "liver_df['Gender'] = liver_df['Gender'].apply(lambda x:1 if x=='Male' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_df['Dataset'] = liver_df['Dataset'].map({1:0, 2:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65       0              0.7               0.1                   187   \n",
       "1   62       1             10.9               5.5                   699   \n",
       "2   62       1              7.3               4.1                   490   \n",
       "3   58       1              1.0               0.4                   182   \n",
       "4   72       1              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        0  \n",
       "1      3.2                        0.74        0  \n",
       "2      3.3                        0.89        0  \n",
       "3      3.4                        1.00        0  \n",
       "4      2.4                        0.40        0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liver_df.drop(['Dataset'], axis=1)\n",
    "y = liver_df['Dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65       0              0.7               0.1                   187   \n",
       "1   62       1             10.9               5.5                   699   \n",
       "2   62       1              7.3               4.1                   490   \n",
       "3   58       1              1.0               0.4                   182   \n",
       "4   72       1              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  \n",
       "0      3.3                        0.90  \n",
       "1      3.2                        0.74  \n",
       "2      3.3                        0.89  \n",
       "3      3.4                        1.00  \n",
       "4      2.4                        0.40  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scalling \n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 10)\n",
      "(408,)\n",
      "(175, 10)\n",
      "(175,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Score: \n",
      " 71.32\n",
      "Logistic Regression Test Score: \n",
      " 71.43\n",
      "Coefficient: \n",
      " [[-0.00787347 -0.07582255 -0.00682583 -0.33506489 -0.00090379 -0.01076544\n",
      "  -0.00241662 -0.32658274  0.71863229 -0.08810998]]\n",
      "Intercept: \n",
      " [0.57342832]\n",
      "Accuracy: \n",
      " 0.7142857142857143\n",
      "Confusion Matrix: \n",
      " [[116  12]\n",
      " [ 38   9]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       128\n",
      "           1       0.43      0.19      0.26        47\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       175\n",
      "   macro avg       0.59      0.55      0.54       175\n",
      "weighted avg       0.67      0.71      0.67       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Create logistic regression object\n",
    "logreg = LogisticRegression()\n",
    "# Train the model using the training sets and check score\n",
    "logreg.fit(X_train, y_train)\n",
    "#Predict Output\n",
    "log_predicted= logreg.predict(X_test)\n",
    "\n",
    "logreg_score = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "logreg_score_test = round(logreg.score(X_test, y_test) * 100, 2)\n",
    "#Equation coefficient and Intercept\n",
    "print('Logistic Regression Training Score: \\n', logreg_score)\n",
    "print('Logistic Regression Test Score: \\n', logreg_score_test)\n",
    "print('Coefficient: \\n', logreg.coef_)\n",
    "print('Intercept: \\n', logreg.intercept_)\n",
    "print('Accuracy: \\n', accuracy_score(y_test,log_predicted))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,log_predicted))\n",
    "print('Classification Report: \\n', classification_report(y_test,log_predicted))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,log_predicted),annot=True,fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest\n",
    "\n",
    "# random_forest = RandomForestClassifier(n_estimators=100)\n",
    "# random_forest.fit(X_train, y_train)\n",
    "# #Predict Output\n",
    "# rf_predicted = random_forest.predict(X_test)\n",
    "\n",
    "# random_forest_score = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "# random_forest_score_test = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "# print('Random Forest Score: \\n', random_forest_score)\n",
    "# print('Random Forest Test Score: \\n', random_forest_score_test)\n",
    "# print('Accuracy: \\n', accuracy_score(y_test,rf_predicted))\n",
    "# print(confusion_matrix(y_test,rf_predicted))\n",
    "# print(classification_report(y_test,rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for  LogisticRegression\n",
    "log_reg_grid = {\n",
    "    \"C\" : np.logspace(-4, 4, 20),\n",
    "    \"solver\" : [\"liblinear\",\"newton-cg\",\"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "/Users/vishwasmore/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'C': array([1.00000e-04, 2.63665e-04, 6.95193e-04, 1.83298e-03, 4.83293e-03,\n",
       "       1.27427e-02, 3.35982e-02, 8.85867e-02, 2.33572e-01, 6.15848e-01,\n",
       "       1.62378e+00, 4.28133e+00, 1.12884e+01, 2.97635e+01, 7.84760e+01,\n",
       "       2.06914e+02, 5.45559e+02, 1.43845e+03, 3.79269e+03, 1.00000e+04]), 'solver': ['liblinear', 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=True)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameters search for Logistic Regression\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions = log_reg_grid,\n",
    "                                cv = 5,\n",
    "                                verbose = True)\n",
    "\n",
    "# Fit random hyperparameter search model for LogisticRegression\n",
    "rs_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'newton-cg', 'C': 0.615848211066026}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Score: \n",
      " 72.3\n",
      "Logistic Regression Test Score: \n",
      " 72.0\n",
      "Coefficient: \n",
      " [[-0.01078561 -0.12888152 -0.01137218 -0.31778551 -0.00102572 -0.0108438\n",
      "  -0.00268826 -0.42102983  0.78460683 -0.23134072]]\n",
      "Intercept: \n",
      " [1.33759493]\n",
      "Accuracy: \n",
      " 0.72\n",
      "Confusion Matrix: \n",
      " [[115  13]\n",
      " [ 36  11]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       128\n",
      "           1       0.46      0.23      0.31        47\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       175\n",
      "   macro avg       0.61      0.57      0.57       175\n",
      "weighted avg       0.68      0.72      0.69       175\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Create logistic regression object\n",
    "logreg = LogisticRegression(solver='newton-cg', C=0.615848211066026)\n",
    "# Train the model using the training sets and check score\n",
    "logreg.fit(X_train, y_train)\n",
    "#Predict Output\n",
    "log_predicted= logreg.predict(X_test)\n",
    "\n",
    "logreg_score = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "logreg_score_test = round(logreg.score(X_test, y_test) * 100, 2)\n",
    "#Equation coefficient and Intercept\n",
    "print('Logistic Regression Training Score: \\n', logreg_score)\n",
    "print('Logistic Regression Test Score: \\n', logreg_score_test)\n",
    "print('Coefficient: \\n', logreg.coef_)\n",
    "print('Intercept: \\n', logreg.intercept_)\n",
    "print('Accuracy: \\n', accuracy_score(y_test,log_predicted))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test,log_predicted))\n",
    "print('Classification Report: \\n', classification_report(y_test,log_predicted))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,log_predicted),annot=True,fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['livermodel']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dumping Model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(logreg,\"livermodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
